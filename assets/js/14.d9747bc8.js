(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{415:function(s,t,a){"use strict";a.r(t);var n=a(25),r=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#一、前言"}},[s._v("一、前言")])]),a("li",[a("a",{attrs:{href:"#二、url去重及策略简介"}},[s._v("二、url去重及策略简介")])])])]),a("p"),s._v(" "),a("h3",{attrs:{id:"一、前言"}},[a("strong",[s._v("一、前言")])]),s._v(" "),a("p",[s._v("今天给大家分享的是，Python爬虫里url去重策略及实现。")]),s._v(" "),a("h3",{attrs:{id:"二、url去重及策略简介"}},[a("strong",[s._v("二、url去重及策略简介")])]),s._v(" "),a("h5",{attrs:{id:"_1-url去重"}},[a("strong",[s._v("1.url去重")])]),s._v(" "),a("p",[s._v("从字面上理解，url去重即去除重复的url,在爬虫中就是去除已经爬取过的url,避免重复爬取，既影响爬虫效率，又产生冗余数据。")]),s._v(" "),a("h5",{attrs:{id:"_2-url去重策略"}},[a("strong",[s._v("2.url去重策略")])]),s._v(" "),a("p",[s._v("从表面上看，url去重策略就是消除url重复的方法，常见的url去重策略有五种，如下：")]),s._v(" "),a("p",[s._v("# 1.将访问过的ur保存到数据库中")]),s._v(" "),a("h1",{attrs:{id:"_2-将访问过的ur保存到set-集合-中-只需要o-1-的代价就可以查询url"}},[s._v("2.将访问过的ur保存到set(集合)中,只需要o(1)的代价就可以查询url")]),s._v(" "),a("h1",{attrs:{id:"_10000000-2byte-50个字符-1024-1024-1024-9g"}},[s._v("10000000*2byte*50个字符/1024/1024/1024=9G")]),s._v(" "),a("h1",{attrs:{id:"_3-url经过md5等方法哈希后保存到set中"}},[s._v("3.url经过md5等方法哈希后保存到set中")]),s._v(" "),a("h1",{attrs:{id:"_4-用-bitmap方法-将访问过的ur通过hash函数映射到某一位"}},[s._v("4.用 bitmap方法,将访问过的ur通过hash函数映射到某一位")]),s._v(" "),a("h1",{attrs:{id:"_5-bloomfilter方法对-bitmap进行改进-多重hash函数降低冲突"}},[s._v("5. bloomfilter方法对 bitmap进行改进,多重hash函数降低冲突")]),s._v(" "),a("h3",{attrs:{id:"三、看代码，边学边敲边记url去重策略"}},[a("strong",[s._v("三、看代码，边学边敲边记url去重策略")])]),s._v(" "),a("h6",{attrs:{id:"_1-将访问过的ur保存到数据库中（初学使用）"}},[a("strong",[s._v("1.将访问过的ur保存到数据库中（初学使用）")])]),s._v(" "),a("p",[s._v("实现起来最简单，但效率最低。 其核心思想是，把页面上爬取到的每个 "),a("code",[s._v("url")]),s._v("存储到数据库，为了避免重复，每次存储前都要遍历查询数据库中是否已经存在当前"),a("code",[s._v("url")]),s._v("（即是否已经爬取过了）,若存在，则不保存，否则，保存当前"),a("code",[s._v("url")]),s._v(",继续保存下一条，直至结束。")]),s._v(" "),a("h6",{attrs:{id:"_2-将访问过的ur保存到set内存中"}},[a("strong",[s._v("2.将访问过的ur保存到set内存中")])]),s._v(" "),a("p",[s._v("将访问过的ur保存到set中,只需要o(1)的代价就可以查询url，取url方便快速，基本不用查询，但是随着存储的url越来越多，占用内存会越来越大。")]),s._v(" "),a("p",[s._v("# 简单计算：假设有1亿条url,每个url平均长度为50个字符，python里unicode编码，每个字符16位，占2")]),s._v(" "),a("h1",{attrs:{id:"个字节（byte）"}},[s._v("个字节（byte）")]),s._v(" "),a("h1",{attrs:{id:"计算式：10-8-x-50个字符-x-2个byte-1024-1024-1024-9g"}},[s._v("计算式：10^8 x 50个字符 x 2个byte / 1024 / 1024 / 1024 = 9G")]),s._v(" "),a("h1",{attrs:{id:"b-m-g"}},[s._v("B      M      G")]),s._v(" "),a("p",[s._v("如果是亿个url,那么占用内存将达G，也不是特别方便，适合小型爬虫。")]),s._v(" "),a("h6",{attrs:{id:"_3-url经过md5缩减到固定长度"}},[a("strong",[s._v("3.url经过md5缩减到固定长度")])]),s._v(" "),a("p",[s._v("'''\n简单计算：一个url经MD5转换，变成一个128bit(位)的字符串，占16byte(字节)，方法二中一个url保守\n估计占50个字符 x 2 = 100byte(字节)，\n计算式： 这样一比较，MD5的空间节省率为：（100-16）/100 = 84%（相比于方法二）\n(Scrapy框架url去重就是采用的类似方法)\n'''")]),s._v(" "),a("h1",{attrs:{id:"维基百科看md5算法"}},[s._v("维基百科看MD5算法")]),s._v(" "),a("p",[s._v("'''\nMD5概述\n设计者 : 罗纳德·李维斯特\n首次发布 : 1992年4月\n系列 : MD, MD2, MD3, MD4, MD5\n编码长度 : 128位\n结构 :　Merkle–Damgård construction\nMD5消息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可\n以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。MD5由美国密码学家\n罗纳德·李维斯特（Ronald Linn Rivest）设计，于1992年公开，用以取代MD4算法。这套算法的程序在\nRFC 1321 中被加以规范。\n将数据（如一段文字）运算变为另一固定长度值，是散列算法的基础原理。\n'''")]),s._v(" "),a("p",[s._v("MD5使用实例：")]),s._v(" "),a("p",[s._v("# 在python3中使用hashlib模块进行md5操作\nimport hashlib")]),s._v(" "),a("h1",{attrs:{id:"待加密信息"}},[s._v("待加密信息")]),s._v(" "),a("p",[s._v("str01 = 'This is your md5 password!'")]),s._v(" "),a("h1",{attrs:{id:"创建md5对象"}},[s._v("创建md5对象")]),s._v(" "),a("p",[s._v("md5_obj = hashlib.md5()")]),s._v(" "),a("h1",{attrs:{id:"进行md5加密前必须-encode-编码-，python里默认是unicode编码，必须转换成utf-8"}},[s._v("进行MD5加密前必须 encode(编码)，python里默认是unicode编码，必须转换成utf-8")]),s._v(" "),a("h1",{attrs:{id:"否则报错：typeerror-unicode-objects-must-be-encoded-before-hashing"}},[s._v("否则报错：TypeError: Unicode-objects must be encoded before hashing")]),s._v(" "),a("p",[s._v("md5_obj.update(str01.encode(encoding='utf-8'))")]),s._v(" "),a("p",[s._v("print('XksA的原话为 ：' + str01)\nprint('MD5加密后为 ：' + md5_obj.hexdigest())")]),s._v(" "),a("h1",{attrs:{id:"result-："}},[s._v("result　：")]),s._v(" "),a("h1",{attrs:{id:"xksa的原话为-：this-is-your-md5-password"}},[s._v("XksA的原话为 ：This is your md5 password!")]),s._v(" "),a("h1",{attrs:{id:"md5加密后为-：0a5f76e7b0f352e47fed559f904c9159"}},[s._v("MD5加密后为 ：0a5f76e7b0f352e47fed559f904c9159")]),s._v(" "),a("h6",{attrs:{id:"_4-用-bitmap方法-将访问过的ur通过hash函数映射到某一位-2"}},[a("strong",[s._v("4.用 bitmap方法,将访问过的ur通过hash函数映射到某一位")])]),s._v(" "),a("p",[s._v("'''\n实现原理：通过hash函数，将每个url映射到一个hash位置中，一个hash位可以只占用一个bit(位)大小，那\n么相对于方法三：一个url占128bit(位)，hash函数法的空间节省成百倍增长。\n计算式：这样一比较，bitmap方法的空间节省率为：\n（128-1）/128= 99.2%(相比于方法三)\n（100 * 8 - 1）/（100*8）= 99.88%（相比于方法一）\n##   (缺点：容易产生冲突)  ##\n'''")]),s._v(" "),a("h1",{attrs:{id:"维基百科看hash-函数"}},[s._v("维基百科看Hash 函数")]),s._v(" "),a("p",[s._v("'''\nhash函数：\n散列函数（英语：Hash function）又称散列算法、哈希函数，是一种从任何一种数据中创建小的数字“指纹”\n的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将数据打乱混\n合，重新创建一个叫做散列值（hash values，hash codes，hash sums，或hashes）的指纹。散列值通常\n用一个短的随机字母和数字组成的字符串来代表。好的散列函数在输入域中很少出现散列冲突。在散列表和数\n据处理中，不抑制冲突来区别数据，会使得数据库记录更难找到。\n'''")]),s._v(" "),a("h6",{attrs:{id:"_5-bloomfilter方法对-bitmap进行改进-多重hash函数降低冲突-2"}},[a("strong",[s._v("5.bloomfilter方法对 bitmap进行改进,多重hash函数降低冲突")])]),s._v(" "),a("p",[s._v("# 维基百科看Bloomfilter\n'''")]),s._v(" "),a("h1",{attrs:{id:"基本概述"}},[s._v("基本概述")]),s._v(" "),a("p",[s._v("如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。\n链表、树、散列表（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，\n我们需要的存储空间越来越大。同时检索速度也越来越慢，上述三种结构的检索时间复杂度分别为：\nO(n),O(log n),O(n/k)")]),s._v(" "),a("h1",{attrs:{id:"原理概述"}},[s._v("原理概述")]),s._v(" "),a("p",[s._v("布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个\n点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点\n有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。")]),s._v(" "),a("h1",{attrs:{id:"优缺点"}},[s._v("优缺点")]),s._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[s._v("布隆过滤器可以用于检索一个元素是否在一个集合中。\n优点是空间效率和查询时间都远远超过一般的算法。\n缺点是有一定的误识别率和删除困难。\n")])])]),a("p",[s._v("'''")]),s._v(" "),a("h1",{attrs:{id:"bloomfilter介绍还可以看这里：https-blog-csdn-net-preyta-article-details-72804148"}},[s._v("Bloomfilter介绍还可以看这里：https://blog.csdn.net/preyta/article/details/72804148")]),s._v(" "),a("p",[s._v("Bloomfilter底层实现：")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 源码地址：https://github.com/preytaren/fastbloom/blob/master/fastbloom/bloomfilter.py")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" math\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" logging\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" functools\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pyhash\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" bitset "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" MmapBitSet\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" hash_tools "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" hashes\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BloomFilter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    A bloom filter implementation,\n    which use Murmur hash and Spooky hash\n    """')]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" capacity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" error_rate"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0001")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" fname"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                 h1"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("pyhash"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("murmur3_x64_128"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" h2"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("pyhash"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("spooky_128"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        :param capacity: size of possible input elements\n        :param error_rate: posi\n        :param fname:\n        :param h1:\n        :param h2:\n        """')]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# calculate m & k")]),s._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("capacity "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" capacity\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("error_rate "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" error_rate\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num_of_bits"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num_of_hashes "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_adjust_param"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                                                                  error_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_fname "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" fname\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data_store "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MmapBitSet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num_of_bits"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data_store"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_hashes "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" functools"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("partial"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hashes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" h1"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("h1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" h2"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("h2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" number"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num_of_hashes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("_adjust_param")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" bits_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" expected_error_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        adjust k & m through 4 steps:\n        1. Choose a ballpark value for n\n        2. Choose a value for m\n        3. Calculate the optimal value of k\n        4. Calculate the error rate for our chosen values of n, m, and k.\n           If it\'s unacceptable, return to step 2 and change m;\n           otherwise we\'re done.\n        in every loop, m = m * 2\n        :param bits_size:\n        :param expected_error_rate:\n        :return:\n        """')]),s._v("\n        n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" estimated_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" estimated_k"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" error_rate "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("capacity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("bits_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n        weight"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" e "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" math"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" math"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("exp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" error_rate "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" expected_error_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            estimated_m "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*=")]),s._v(" \n            estimated_k "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("estimated_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" weight"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" \n            error_rate "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" math"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("exp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("estimated_k "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" estimated_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v(" estimated_k\n            logging"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("estimated_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" estimated_k"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" error_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" estimated_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" estimated_k\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        add a string to bloomfilter\n        :param msg:\n        :return:\n        """')]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            msg "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        positions "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" _hash_value "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_hashes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            positions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("_hash_value "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num_of_bits"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" pos "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sorted")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("positions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data_store"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("set")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pos"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@staticmethod")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" fname"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fname"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" fp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" NotImplementedError\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("__str__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        output bitset directly\n        :return:\n        """')]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("__contains__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            msg "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        positions "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" _hash_value "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_hashes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            positions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("_hash_value "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num_of_bits"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" position "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sorted")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("positions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data_store"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("__len__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_size\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br"),a("span",{staticClass:"line-number"},[s._v("45")]),a("br"),a("span",{staticClass:"line-number"},[s._v("46")]),a("br"),a("span",{staticClass:"line-number"},[s._v("47")]),a("br"),a("span",{staticClass:"line-number"},[s._v("48")]),a("br"),a("span",{staticClass:"line-number"},[s._v("49")]),a("br"),a("span",{staticClass:"line-number"},[s._v("50")]),a("br"),a("span",{staticClass:"line-number"},[s._v("51")]),a("br"),a("span",{staticClass:"line-number"},[s._v("52")]),a("br"),a("span",{staticClass:"line-number"},[s._v("53")]),a("br"),a("span",{staticClass:"line-number"},[s._v("54")]),a("br"),a("span",{staticClass:"line-number"},[s._v("55")]),a("br"),a("span",{staticClass:"line-number"},[s._v("56")]),a("br"),a("span",{staticClass:"line-number"},[s._v("57")]),a("br"),a("span",{staticClass:"line-number"},[s._v("58")]),a("br"),a("span",{staticClass:"line-number"},[s._v("59")]),a("br"),a("span",{staticClass:"line-number"},[s._v("60")]),a("br"),a("span",{staticClass:"line-number"},[s._v("61")]),a("br"),a("span",{staticClass:"line-number"},[s._v("62")]),a("br"),a("span",{staticClass:"line-number"},[s._v("63")]),a("br"),a("span",{staticClass:"line-number"},[s._v("64")]),a("br"),a("span",{staticClass:"line-number"},[s._v("65")]),a("br"),a("span",{staticClass:"line-number"},[s._v("66")]),a("br"),a("span",{staticClass:"line-number"},[s._v("67")]),a("br"),a("span",{staticClass:"line-number"},[s._v("68")]),a("br"),a("span",{staticClass:"line-number"},[s._v("69")]),a("br"),a("span",{staticClass:"line-number"},[s._v("70")]),a("br"),a("span",{staticClass:"line-number"},[s._v("71")]),a("br"),a("span",{staticClass:"line-number"},[s._v("72")]),a("br"),a("span",{staticClass:"line-number"},[s._v("73")]),a("br"),a("span",{staticClass:"line-number"},[s._v("74")]),a("br"),a("span",{staticClass:"line-number"},[s._v("75")]),a("br"),a("span",{staticClass:"line-number"},[s._v("76")]),a("br"),a("span",{staticClass:"line-number"},[s._v("77")]),a("br"),a("span",{staticClass:"line-number"},[s._v("78")]),a("br"),a("span",{staticClass:"line-number"},[s._v("79")]),a("br"),a("span",{staticClass:"line-number"},[s._v("80")]),a("br"),a("span",{staticClass:"line-number"},[s._v("81")]),a("br"),a("span",{staticClass:"line-number"},[s._v("82")]),a("br"),a("span",{staticClass:"line-number"},[s._v("83")]),a("br"),a("span",{staticClass:"line-number"},[s._v("84")]),a("br"),a("span",{staticClass:"line-number"},[s._v("85")]),a("br"),a("span",{staticClass:"line-number"},[s._v("86")]),a("br"),a("span",{staticClass:"line-number"},[s._v("87")]),a("br"),a("span",{staticClass:"line-number"},[s._v("88")]),a("br"),a("span",{staticClass:"line-number"},[s._v("89")]),a("br"),a("span",{staticClass:"line-number"},[s._v("90")]),a("br"),a("span",{staticClass:"line-number"},[s._v("91")]),a("br"),a("span",{staticClass:"line-number"},[s._v("92")]),a("br"),a("span",{staticClass:"line-number"},[s._v("93")]),a("br"),a("span",{staticClass:"line-number"},[s._v("94")]),a("br"),a("span",{staticClass:"line-number"},[s._v("95")]),a("br"),a("span",{staticClass:"line-number"},[s._v("96")]),a("br"),a("span",{staticClass:"line-number"},[s._v("97")]),a("br")])])])}),[],!1,null,null,null);t.default=r.exports}}]);