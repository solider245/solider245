<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>如何用Python爬数据？（一）网页抓取 | 吴起的个人网站</title>
    <meta name="generator" content="VuePress 1.5.2">
    <link rel="icon" href="https://images-1255533533.cos.ap-shanghai.myqcloud.com/20190817214528_05c52e04cf64654248918bfc2a1f64ab.png">
    <link rel="manifest" href="/VuePress-blog/manifest.json">
    <link rel="apple-touch-icon" href="/VuePress-blog/icons/apple-touch-icon-152x152.png">
    <link rel="mask-icon" href="/VuePress-blog/icons/safari-pinned-tab.svg" color="#3eaf7c">
    <meta name="description" content="在此处添描述">
    <meta name="author" content="中箭的吴起">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
    <meta name="msapplication-TileColor" content="#000000">
    <link rel="preload" href="/VuePress-blog/assets/css/0.styles.f7cbc213.css" as="style"><link rel="preload" href="/VuePress-blog/assets/js/app.e4354aa1.js" as="script"><link rel="preload" href="/VuePress-blog/assets/js/2.398f4283.js" as="script"><link rel="preload" href="/VuePress-blog/assets/js/55.bf5c3551.js" as="script"><link rel="prefetch" href="/VuePress-blog/assets/js/10.f88a1831.js"><link rel="prefetch" href="/VuePress-blog/assets/js/100.618f4056.js"><link rel="prefetch" href="/VuePress-blog/assets/js/101.b170cbee.js"><link rel="prefetch" href="/VuePress-blog/assets/js/102.8cd82e5b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/103.a9e55775.js"><link rel="prefetch" href="/VuePress-blog/assets/js/104.2b910c17.js"><link rel="prefetch" href="/VuePress-blog/assets/js/105.badde638.js"><link rel="prefetch" href="/VuePress-blog/assets/js/106.cabb5a4b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/107.55916750.js"><link rel="prefetch" href="/VuePress-blog/assets/js/108.a894756d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/109.665bfa12.js"><link rel="prefetch" href="/VuePress-blog/assets/js/11.82bfc211.js"><link rel="prefetch" href="/VuePress-blog/assets/js/110.82d9d03d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/111.a3bf7bb5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/112.308d5801.js"><link rel="prefetch" href="/VuePress-blog/assets/js/113.aaf33f56.js"><link rel="prefetch" href="/VuePress-blog/assets/js/114.896dc3c8.js"><link rel="prefetch" href="/VuePress-blog/assets/js/115.33bf424e.js"><link rel="prefetch" href="/VuePress-blog/assets/js/116.6a8b1073.js"><link rel="prefetch" href="/VuePress-blog/assets/js/117.00678fec.js"><link rel="prefetch" href="/VuePress-blog/assets/js/118.6bc9e989.js"><link rel="prefetch" href="/VuePress-blog/assets/js/119.31a2372f.js"><link rel="prefetch" href="/VuePress-blog/assets/js/12.f528b4f1.js"><link rel="prefetch" href="/VuePress-blog/assets/js/120.d1bd65a5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/121.6ff9895f.js"><link rel="prefetch" href="/VuePress-blog/assets/js/122.f80812c8.js"><link rel="prefetch" href="/VuePress-blog/assets/js/123.457af999.js"><link rel="prefetch" href="/VuePress-blog/assets/js/124.a62fbdae.js"><link rel="prefetch" href="/VuePress-blog/assets/js/125.8d1225d4.js"><link rel="prefetch" href="/VuePress-blog/assets/js/126.9e329698.js"><link rel="prefetch" href="/VuePress-blog/assets/js/127.e3eac40d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/128.73562074.js"><link rel="prefetch" href="/VuePress-blog/assets/js/129.7dc75ed6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/13.0c9fc526.js"><link rel="prefetch" href="/VuePress-blog/assets/js/130.282ea90d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/131.948f43a2.js"><link rel="prefetch" href="/VuePress-blog/assets/js/132.aa7a4d25.js"><link rel="prefetch" href="/VuePress-blog/assets/js/133.0608bab7.js"><link rel="prefetch" href="/VuePress-blog/assets/js/134.4a1bb517.js"><link rel="prefetch" href="/VuePress-blog/assets/js/135.2449e034.js"><link rel="prefetch" href="/VuePress-blog/assets/js/136.018a7818.js"><link rel="prefetch" href="/VuePress-blog/assets/js/137.c586e53d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/138.5b043595.js"><link rel="prefetch" href="/VuePress-blog/assets/js/139.f535affe.js"><link rel="prefetch" href="/VuePress-blog/assets/js/14.d9747bc8.js"><link rel="prefetch" href="/VuePress-blog/assets/js/140.b1f108ce.js"><link rel="prefetch" href="/VuePress-blog/assets/js/141.ce586450.js"><link rel="prefetch" href="/VuePress-blog/assets/js/142.7f88da6d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/143.d3ce1076.js"><link rel="prefetch" href="/VuePress-blog/assets/js/144.b924a878.js"><link rel="prefetch" href="/VuePress-blog/assets/js/145.8f4496ac.js"><link rel="prefetch" href="/VuePress-blog/assets/js/146.f77f5ae7.js"><link rel="prefetch" href="/VuePress-blog/assets/js/147.8892e259.js"><link rel="prefetch" href="/VuePress-blog/assets/js/148.ac76523d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/149.036ba33d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/15.0ec2a8ee.js"><link rel="prefetch" href="/VuePress-blog/assets/js/150.ec99cda4.js"><link rel="prefetch" href="/VuePress-blog/assets/js/151.6b1887cc.js"><link rel="prefetch" href="/VuePress-blog/assets/js/152.3c509f41.js"><link rel="prefetch" href="/VuePress-blog/assets/js/153.470b653b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/154.d79fdff7.js"><link rel="prefetch" href="/VuePress-blog/assets/js/155.42fb4d54.js"><link rel="prefetch" href="/VuePress-blog/assets/js/156.ce6ca9d0.js"><link rel="prefetch" href="/VuePress-blog/assets/js/157.5da875cb.js"><link rel="prefetch" href="/VuePress-blog/assets/js/158.95349a8a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/159.c6d5d3f6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/16.96972e23.js"><link rel="prefetch" href="/VuePress-blog/assets/js/160.fd6be3d0.js"><link rel="prefetch" href="/VuePress-blog/assets/js/161.645951a6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/162.f91af681.js"><link rel="prefetch" href="/VuePress-blog/assets/js/163.4ff37798.js"><link rel="prefetch" href="/VuePress-blog/assets/js/164.0ab0411b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/165.fb3e31ca.js"><link rel="prefetch" href="/VuePress-blog/assets/js/166.0e89f139.js"><link rel="prefetch" href="/VuePress-blog/assets/js/167.6910f6cf.js"><link rel="prefetch" href="/VuePress-blog/assets/js/168.dba298af.js"><link rel="prefetch" href="/VuePress-blog/assets/js/169.c8da94cc.js"><link rel="prefetch" href="/VuePress-blog/assets/js/17.06889e54.js"><link rel="prefetch" href="/VuePress-blog/assets/js/170.dfc7fbab.js"><link rel="prefetch" href="/VuePress-blog/assets/js/171.75cc843a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/172.3a98f4d2.js"><link rel="prefetch" href="/VuePress-blog/assets/js/173.25f0a60f.js"><link rel="prefetch" href="/VuePress-blog/assets/js/18.db5ae82d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/19.4055eeb9.js"><link rel="prefetch" href="/VuePress-blog/assets/js/20.0b68f787.js"><link rel="prefetch" href="/VuePress-blog/assets/js/21.64b18850.js"><link rel="prefetch" href="/VuePress-blog/assets/js/22.a548f3c5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/23.04a0e73a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/24.109f764e.js"><link rel="prefetch" href="/VuePress-blog/assets/js/25.7fa1c42f.js"><link rel="prefetch" href="/VuePress-blog/assets/js/26.cfaf31c5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/27.ebbc7ee9.js"><link rel="prefetch" href="/VuePress-blog/assets/js/28.51f27455.js"><link rel="prefetch" href="/VuePress-blog/assets/js/29.34168ce5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/3.9fb4597b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/30.96e95f78.js"><link rel="prefetch" href="/VuePress-blog/assets/js/31.63fbbffa.js"><link rel="prefetch" href="/VuePress-blog/assets/js/32.649cbad2.js"><link rel="prefetch" href="/VuePress-blog/assets/js/33.f7e81235.js"><link rel="prefetch" href="/VuePress-blog/assets/js/34.ca4331e1.js"><link rel="prefetch" href="/VuePress-blog/assets/js/35.0b860b77.js"><link rel="prefetch" href="/VuePress-blog/assets/js/36.d2f4ba78.js"><link rel="prefetch" href="/VuePress-blog/assets/js/37.c2877be5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/38.b345c513.js"><link rel="prefetch" href="/VuePress-blog/assets/js/39.0a91f037.js"><link rel="prefetch" href="/VuePress-blog/assets/js/4.7fa94338.js"><link rel="prefetch" href="/VuePress-blog/assets/js/40.3540778f.js"><link rel="prefetch" href="/VuePress-blog/assets/js/41.b4236deb.js"><link rel="prefetch" href="/VuePress-blog/assets/js/42.c525cdf5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/43.57682d62.js"><link rel="prefetch" href="/VuePress-blog/assets/js/44.bf75d21a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/45.9b8489e6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/46.e142d725.js"><link rel="prefetch" href="/VuePress-blog/assets/js/47.f5eec595.js"><link rel="prefetch" href="/VuePress-blog/assets/js/48.745b0e5d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/49.86bf2483.js"><link rel="prefetch" href="/VuePress-blog/assets/js/5.587b09c2.js"><link rel="prefetch" href="/VuePress-blog/assets/js/50.b05cd91e.js"><link rel="prefetch" href="/VuePress-blog/assets/js/51.1c8e588d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/52.fa48d599.js"><link rel="prefetch" href="/VuePress-blog/assets/js/53.2b6a2ab1.js"><link rel="prefetch" href="/VuePress-blog/assets/js/54.eb443023.js"><link rel="prefetch" href="/VuePress-blog/assets/js/56.ce341c9a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/57.329c792a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/58.1321afa7.js"><link rel="prefetch" href="/VuePress-blog/assets/js/59.fe23f6db.js"><link rel="prefetch" href="/VuePress-blog/assets/js/6.6fd5799c.js"><link rel="prefetch" href="/VuePress-blog/assets/js/60.0320d1d5.js"><link rel="prefetch" href="/VuePress-blog/assets/js/61.c4846f1c.js"><link rel="prefetch" href="/VuePress-blog/assets/js/62.ff70299a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/63.41cc17ab.js"><link rel="prefetch" href="/VuePress-blog/assets/js/64.082d9540.js"><link rel="prefetch" href="/VuePress-blog/assets/js/65.1c25d870.js"><link rel="prefetch" href="/VuePress-blog/assets/js/66.7014dd6b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/67.71c256c6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/68.90d240a2.js"><link rel="prefetch" href="/VuePress-blog/assets/js/69.5047f2f6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/7.6ba377b6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/70.be70817b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/71.1c9efc31.js"><link rel="prefetch" href="/VuePress-blog/assets/js/72.b3eb16bb.js"><link rel="prefetch" href="/VuePress-blog/assets/js/73.b72b7959.js"><link rel="prefetch" href="/VuePress-blog/assets/js/74.bb6bdbfd.js"><link rel="prefetch" href="/VuePress-blog/assets/js/75.18b81eb3.js"><link rel="prefetch" href="/VuePress-blog/assets/js/76.fc2302e3.js"><link rel="prefetch" href="/VuePress-blog/assets/js/77.c0bd9e33.js"><link rel="prefetch" href="/VuePress-blog/assets/js/78.c339860d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/79.23c005e6.js"><link rel="prefetch" href="/VuePress-blog/assets/js/8.7a42445d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/80.838feb78.js"><link rel="prefetch" href="/VuePress-blog/assets/js/81.1b93e8a9.js"><link rel="prefetch" href="/VuePress-blog/assets/js/82.13eb4655.js"><link rel="prefetch" href="/VuePress-blog/assets/js/83.201aba60.js"><link rel="prefetch" href="/VuePress-blog/assets/js/84.ac1d8d4d.js"><link rel="prefetch" href="/VuePress-blog/assets/js/85.dd526c02.js"><link rel="prefetch" href="/VuePress-blog/assets/js/86.1ff01b81.js"><link rel="prefetch" href="/VuePress-blog/assets/js/87.668a3110.js"><link rel="prefetch" href="/VuePress-blog/assets/js/88.1a20f59b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/89.da33bb07.js"><link rel="prefetch" href="/VuePress-blog/assets/js/9.053b461b.js"><link rel="prefetch" href="/VuePress-blog/assets/js/90.4ec9f95f.js"><link rel="prefetch" href="/VuePress-blog/assets/js/91.818e056a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/92.3fe61856.js"><link rel="prefetch" href="/VuePress-blog/assets/js/93.458534e9.js"><link rel="prefetch" href="/VuePress-blog/assets/js/94.8849d84e.js"><link rel="prefetch" href="/VuePress-blog/assets/js/95.be1f911a.js"><link rel="prefetch" href="/VuePress-blog/assets/js/96.295835c7.js"><link rel="prefetch" href="/VuePress-blog/assets/js/97.6cb68243.js"><link rel="prefetch" href="/VuePress-blog/assets/js/98.056edaa4.js"><link rel="prefetch" href="/VuePress-blog/assets/js/99.34645cba.js">
    <link rel="stylesheet" href="/VuePress-blog/assets/css/0.styles.f7cbc213.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/VuePress-blog/" class="home-link router-link-active"><!----> <span class="site-name">吴起的个人网站</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文章转载" class="dropdown-title"><span class="title">文章转载</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/" class="nav-link">
  首页
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/Linux常见命令/" class="nav-link">
  Linux常见命令
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/Linux常用软件/" class="nav-link">
  Linux常用软件
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/docker/" class="nav-link">
  docker
</a></li><li class="dropdown-item"><h4>
          Vim
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/VuePress-blog/文章转载/Vim/vim文章/" class="nav-link">
  vim文章
</a></li><li class="dropdown-subitem"><a href="/VuePress-blog/文章转载/Vim/vim配置/" class="nav-link">
  vim配置
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="常见问题" class="dropdown-title"><span class="title">常见问题</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/客户端科学上网/" class="nav-link">
  客户端科学上网
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/命令行科学上网/" class="nav-link">
  命令行科学上网
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/镜像加速大全/" class="nav-link">
  镜像加速大全
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/Git/" class="nav-link">
  Git
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/vim/" class="nav-link">
  vim
</a></li><li class="dropdown-item"><h4>
          Pyhton
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/VuePress-blog/常见问题/Python/" class="nav-link">
  Pyhton
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="python" class="dropdown-title"><span class="title">python</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/Python/" class="nav-link router-link-active">
  首页
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/Python/最新转载/" class="nav-link">
  最新转载
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/Python/爬虫案例/" class="nav-link">
  爬虫案例
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="个人原创" class="dropdown-title"><span class="title">个人原创</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/个人原创/" class="nav-link">
  个人原创
</a></li></ul></div></div> <a href="https://github.com/solider245/VuePress-blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    Repo
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文章转载" class="dropdown-title"><span class="title">文章转载</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/" class="nav-link">
  首页
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/Linux常见命令/" class="nav-link">
  Linux常见命令
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/Linux常用软件/" class="nav-link">
  Linux常用软件
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/文章转载/docker/" class="nav-link">
  docker
</a></li><li class="dropdown-item"><h4>
          Vim
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/VuePress-blog/文章转载/Vim/vim文章/" class="nav-link">
  vim文章
</a></li><li class="dropdown-subitem"><a href="/VuePress-blog/文章转载/Vim/vim配置/" class="nav-link">
  vim配置
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="常见问题" class="dropdown-title"><span class="title">常见问题</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/客户端科学上网/" class="nav-link">
  客户端科学上网
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/命令行科学上网/" class="nav-link">
  命令行科学上网
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/镜像加速大全/" class="nav-link">
  镜像加速大全
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/Git/" class="nav-link">
  Git
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/常见问题/vim/" class="nav-link">
  vim
</a></li><li class="dropdown-item"><h4>
          Pyhton
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/VuePress-blog/常见问题/Python/" class="nav-link">
  Pyhton
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="python" class="dropdown-title"><span class="title">python</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/Python/" class="nav-link router-link-active">
  首页
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/Python/最新转载/" class="nav-link">
  最新转载
</a></li><li class="dropdown-item"><!----> <a href="/VuePress-blog/Python/爬虫案例/" class="nav-link">
  爬虫案例
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="个人原创" class="dropdown-title"><span class="title">个人原创</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/VuePress-blog/个人原创/" class="nav-link">
  个人原创
</a></li></ul></div></div> <a href="https://github.com/solider245/VuePress-blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    Repo
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>爬虫案例</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/VuePress-blog/Python/爬虫案例/Python时间模块新手指南.html" class="sidebar-link">Python时间模块新手指南</a></li><li><a href="/VuePress-blog/Python/爬虫案例/Python爬取“爆款剧”——《三十而已》热评，并做可视化.html" class="sidebar-link">Python爬取“爆款剧”——《三十而已》热评，并做可视化</a></li><li><a href="/VuePress-blog/Python/爬虫案例/Python爬虫入门实战之猫眼电影数据抓取.html" class="sidebar-link">Python爬虫入门实战之猫眼电影数据抓取（实战篇）.md</a></li><li><a href="/VuePress-blog/Python/%E7%88%AC%E8%99%AB%E6%A1%88%E4%BE%8B/" aria-current="page" class="sidebar-link">爬虫案例的首页</a></li><li><a href="/VuePress-blog/Python/爬虫案例/python 爬虫之requests爬取页面图片的url，并将图片下载到本地.html" class="sidebar-link">python 爬虫之requests爬取页面图片的url，并将图片下载到本地</a></li><li><a href="/VuePress-blog/Python/爬虫案例/python3爬虫猫眼电影爬取-破解字符集反爬.html" class="sidebar-link">【python3爬虫】猫眼电影爬取（破解字符集反爬）</a></li><li><a href="/VuePress-blog/Python/爬虫案例/python战反爬虫-爬取猫眼电影数据（Requests, BeautifulSoup, MySQLdb,re等库).html" class="sidebar-link">python战反爬虫：爬取猫眼电影数据 (二）（Requests, BeautifulSoup, MySQLdb,re等库)</a></li><li><a href="/VuePress-blog/Python/爬虫案例/python爬取网站全部url链接.html" class="sidebar-link">python爬取网站全部url链接</a></li><li><a href="/VuePress-blog/Python/爬虫案例/python爬虫之pandas.html" class="sidebar-link">python爬虫之pandas</a></li><li><a href="/VuePress-blog/Python/爬虫案例/python爬虫爬取全站url，完美小demo.html" class="sidebar-link">python爬虫爬取全站url，完美小demo（可防止链接到外网等各种强大筛选）</a></li><li><a href="/VuePress-blog/Python/爬虫案例/【已解决】写Python爬虫爬取汽车之家品牌车系车型数据.html" class="sidebar-link">【已解决】写Python爬虫爬取汽车之家品牌车系车型数据</a></li><li><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html" class="active sidebar-link">如何用Python爬数据？（一）网页抓取</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#需求" class="sidebar-link">需求</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#概念" class="sidebar-link">概念</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#目标" class="sidebar-link">目标</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#环境" class="sidebar-link">环境</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#代码" class="sidebar-link">代码</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#小结" class="sidebar-link">小结</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#思考" class="sidebar-link">思考</a></li><li class="sidebar-sub-header"><a href="/VuePress-blog/Python/爬虫案例/如何用Python爬数据-网页抓取.html#讨论" class="sidebar-link">讨论</a></li></ul></li><li><a href="/VuePress-blog/Python/爬虫案例/实战项目 1：5 行代码爬取国内所有上市公司信息.html" class="sidebar-link">实战项目 1：5 行代码爬取国内所有上市公司信息</a></li><li><a href="/VuePress-blog/Python/爬虫案例/放养的小爬虫--豆瓣电影入门级爬虫(mongodb使用教程~).html" class="sidebar-link">放养的小爬虫--豆瓣电影入门级爬虫(mongodb使用教程~)</a></li><li><a href="/VuePress-blog/Python/爬虫案例/爬虫养成记--千军万马来相见-详解多线程.html" class="sidebar-link">爬虫养成记--千军万马来相见（详解多线程）</a></li><li><a href="/VuePress-blog/Python/爬虫案例/爬虫实战01——爬取猫眼电影top100榜单.html" class="sidebar-link">爬虫实战01——爬取猫眼电影top100榜单</a></li><li><a href="/VuePress-blog/Python/爬虫案例/爬虫练习之循环爬取网页中全部链接(requsets同步).html" class="sidebar-link">爬虫练习之循环爬取网页中全部链接(requsets同步)</a></li><li><a href="/VuePress-blog/Python/爬虫案例/猫眼电影爬取(二)requests+beautifulsoup并将数据存储到mysql数据库.html" class="sidebar-link">猫眼电影爬取(二)：requests+beautifulsoup，并将数据存储到mysql数据库</a></li><li><a href="/VuePress-blog/Python/爬虫案例/这可能是你见过的最全的网络爬虫干货总结.html" class="sidebar-link">这可能是你见过的最全的网络爬虫干货总结！</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p></p><div class="table-of-contents"><ul><li><a href="#需求">需求</a></li><li><a href="#概念">概念</a></li><li><a href="#目标">目标</a></li><li><a href="#环境">环境</a></li><li><a href="#代码">代码</a></li><li><a href="#小结">小结</a></li><li><a href="#思考">思考</a></li><li><a href="#讨论">讨论</a></li></ul></div><p></p> <p>你期待已久的Python网络数据爬虫教程来了。本文为你演示如何从网页里找到感兴趣的链接和说明文字，抓取并存储到Excel。</p> <p><img src="https://picb.zhimg.com/v2-666234f85f5a5d58aba107639bdc1664_b.jpg" alt=""></p> <p><img src="https://picb.zhimg.com/80/v2-666234f85f5a5d58aba107639bdc1664_720w.jpg" alt=""></p> <h2 id="需求">需求</h2> <p>我在公众号后台，经常可以收到读者的留言。</p> <p>很多留言，是读者的疑问。只要有时间，我都会抽空尝试解答。</p> <p>但是有的留言，乍看起来就不明所以了。</p> <p>例如下面这个：</p> <p><img src="https://pic1.zhimg.com/v2-766eb7a55b493e8125927e9ca74b035b_b.jpg" alt=""></p> <p><img src="https://pic1.zhimg.com/80/v2-766eb7a55b493e8125927e9ca74b035b_720w.jpg" alt=""></p> <p>一分钟后，他可能觉得不妥（大概因为想起来，我用简体字写文章），于是又用简体发了一遍。</p> <p><img src="https://pic3.zhimg.com/v2-a8f22b837ba61dc7b1b838c308d30ffe_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-a8f22b837ba61dc7b1b838c308d30ffe_720w.jpg" alt=""></p> <p>我恍然大悟。</p> <p>这位读者以为我的公众号设置了关键词推送对应文章功能。所以看了我的其他数据科学教程后，想看“爬虫”专题。</p> <p>不好意思，当时我还没有写爬虫文章。</p> <p>而且，我的公众号暂时也没有设置这种关键词推送。</p> <p>主要是因为我懒。</p> <p>这样的消息接收得多了，我也能体察到读者的需求。不止一个读者表达出对爬虫教程的兴趣。</p> <p>之前提过，目前主流而合法的网络数据收集方法，主要分为3类：</p> <ul><li>开放数据集下载；</li> <li>API读取；</li> <li>爬虫。</li></ul> <p>前两种方法，我都已经做过一些介绍，这次说说爬虫。</p> <p><img src="https://pic3.zhimg.com/v2-18f96100d2cd69d966a32c41259734b2_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-18f96100d2cd69d966a32c41259734b2_720w.jpg" alt=""></p> <h2 id="概念">概念</h2> <p>许多读者对爬虫的定义，有些混淆。咱们有必要辨析一下。</p> <p>维基百科是这么说的：</p> <blockquote><p>网络爬虫（英语：web crawler），也叫网络蜘蛛（spider），是一种用来自动浏览<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25B8%2587%25E7%25BB%25B4%25E7%25BD%2591" target="_blank" rel="noopener noreferrer">万维网<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>的 <a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/w/index.php%3Ftitle%3D%25E7%25BD%2591%25E7%25BB%259C%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%26action%3Dedit%26redlink%3D1" target="_blank" rel="noopener noreferrer">网络机器人<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。其目的一般为编纂<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/w/index.php%3Ftitle%3D%25E7%25BD%2591%25E7%25BB%259C%25E7%25B4%25A2%25E5%25BC%2595%26action%3Dedit%26redlink%3D1" target="_blank" rel="noopener noreferrer">网络索引<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p></blockquote> <p>这问题就来了，你又不打算做搜索引擎，为什么对网络爬虫那么热心呢？</p> <p>其实，许多人口中所说的爬虫（web crawler），跟另外一种功能“网页抓取”（web scraping）搞混了。</p> <p>维基百科上，对于后者这样解释：</p> <blockquote><p>Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser.</p></blockquote> <p>看到没有，即便你用浏览器手动拷贝数据下来，也叫做网页抓取（web scraping）。是不是立刻觉得自己强大了很多？</p> <p>但是，这定义还没完：</p> <blockquote><p>While web scraping can be done manually by a software user, the term typically refers to automate processes implemented using a bot or web crawler.</p></blockquote> <p>也就是说，用爬虫（或者机器人）<strong>自动</strong>替你完成网页抓取工作，才是你真正想要的。</p> <p>数据抓下来干什么呢？</p> <p>一般是先存储起来，放到数据库或者电子表格中，以备检索或者进一步分析使用。</p> <p>所以，你真正想要的功能是这样的：</p> <p>找到链接，获得Web页面，抓取指定信息，存储。</p> <p>这个过程有可能会往复循环，甚至是滚雪球。</p> <p>你希望用自动化的方式来完成它。</p> <p>了解了这一点，你就不要老盯着爬虫不放了。爬虫研制出来，其实是为了给搜索引擎编制索引数据库使用的。你为了抓取点儿数据拿来使用，已经是大炮轰蚊子了。</p> <p>要真正掌握爬虫，你需要具备不少基础知识。例如HTML, CSS, Javascript, 数据结构……</p> <p>这也是为什么我一直犹豫着没有写爬虫教程的原因。</p> <p>不过这两天，看到王烁主编的一段话，很有启发：</p> <blockquote><p>我喜欢讲一个另类二八定律，就是付出两成努力，了解一件事的八成。</p></blockquote> <p>既然我们的目标很明确，就是要从网页抓取数据。那么你需要掌握的<strong>最重要</strong>能力，是拿到一个网页链接后，如何从中快捷有效地抓取自己想要的信息。</p> <p>掌握了它，你还不能说自己已经学会了爬虫。</p> <p>但有了这个基础，你就能比之前更轻松获取数据了。特别是对“文科生”的很多应用场景来说，非常有用。这就是<strong>赋能</strong>。</p> <p>而且，再进一步深入理解爬虫的工作原理，也变得轻松许多。</p> <p>这也算“另类二八定律”的一个应用吧。</p> <p>Python语言的重要特色之一，就是可以利用强大的软件工具包（许多都是第三方提供）。你只需要编写简单的程序，就能自动解析网页，抓取数据。</p> <p>本文给你演示这一过程。</p> <h2 id="目标">目标</h2> <p>要抓取网页数据，我们先制订一个小目标。</p> <p>目标不能太复杂。但是完成它，应该对你理解抓取（Web Scraping）有帮助。</p> <p>就选择我最近发布的一篇简书文章作为抓取对象好了。题目叫做《<a href="https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/85f4624485b9" target="_blank" rel="noopener noreferrer">如何用《玉树芝兰》入门数据科学？<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>》。</p> <p><img src="https://pic3.zhimg.com/v2-3f8f6c1d21846d53fdc8a6543c796e21_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-3f8f6c1d21846d53fdc8a6543c796e21_720w.jpg" alt=""></p> <p>这篇文章里，我把之前的发布的数据科学系列文章做了重新组织和串讲。</p> <p>文中包含很多之前教程的标题和对应链接。例如下图红色边框圈起来的部分。</p> <p><img src="https://pic2.zhimg.com/v2-a3ecb9e710fbd230061f485bd1c1be1e_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-a3ecb9e710fbd230061f485bd1c1be1e_720w.jpg" alt=""></p> <p>假设你对文中提到教程都很感兴趣，希望获得这些文章的链接，并且存储到Excel里，就像下面这个样子：</p> <p><img src="https://pic4.zhimg.com/v2-98e7aed67af306294254ae7e2260a652_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-98e7aed67af306294254ae7e2260a652_720w.jpg" alt=""></p> <p>你需要把非结构化的分散信息（自然语言文本中的链接），专门提取整理，并且存储下来。</p> <p>该怎么办呢？</p> <p>即便不会编程，你也可以全文通读，逐个去找这些文章链接，手动把文章标题、链接都分别拷贝下来，存到Excel表里面。</p> <p>但是，这种手工采集方法<strong>没有效率</strong>。</p> <p>我们用Python。</p> <h2 id="环境">环境</h2> <p>要装Python，比较省事的办法是安装Anaconda套装。</p> <p>请到<a href="https://link.zhihu.com/?target=https%3A//www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">这个网址<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>下载Anaconda的最新版本。</p> <p><img src="https://pic4.zhimg.com/v2-b8d24f74ff9bb63c48eadc26126e364b_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-b8d24f74ff9bb63c48eadc26126e364b_720w.jpg" alt=""></p> <p>请选择左侧的 Python <strong>3.6</strong> 版本下载安装。</p> <p>如果你需要具体的步骤指导，或者想知道Windows平台如何安装并运行Anaconda命令，请参考我为你准备的<a href="https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/772740d57576" target="_blank" rel="noopener noreferrer">视频教程<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p> <p>安装好Anaconda之后，请到<a href="https://link.zhihu.com/?target=https%3A//github.com/wshuyi/demo-python-scrape-webpage-with-requests-html/archive/master.zip" target="_blank" rel="noopener noreferrer">这个网址<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>下载本教程配套的压缩包。</p> <p>下载后解压，你会在生成的目录（下称“演示目录”）里面看到以下三个文件。</p> <p><img src="https://pic4.zhimg.com/v2-4398d384429a230f27edbfe1f6777e14_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-4398d384429a230f27edbfe1f6777e14_720w.jpg" alt=""></p> <p>打开终端，用cd命令进入该<strong>演示目录</strong>。如果你不了解具体使用方法，也可以参考<a href="https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/772740d57576" target="_blank" rel="noopener noreferrer">视频教程<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p> <p>我们需要安装一些环境依赖包。</p> <p>首先执行：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>pip install pipenv
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这里安装的，是一个优秀的 Python 软件包管理工具 pipenv 。</p> <p>安装后，请执行：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>pipenv install
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>看到演示目录下两个Pipfile开头的文件了吗？它们就是 pipenv 的设置文档。</p> <p>pipenv 工具会依照它们，自动为我们安装所需要的全部依赖软件包。</p> <p><img src="https://picb.zhimg.com/v2-35f461359fba39d18da279ce2dfea221_b.jpg" alt=""></p> <p><img src="https://picb.zhimg.com/80/v2-35f461359fba39d18da279ce2dfea221_720w.jpg" alt=""></p> <p>上图里面有个绿色的进度条，提示所需安装软件数量和实际进度。</p> <p>装好后，根据提示我们执行：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>pipenv shell
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>此处请确认你的电脑上已经安装了 Google Chrome 浏览器。</p> <p>我们执行：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>jupyter notebook
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>默认浏览器（Google Chrome）会开启，并启动 Jupyter 笔记本界面：</p> <p><img src="https://pic1.zhimg.com/v2-993752f09bf67b6d8700397f98a83cde_b.jpg" alt=""></p> <p><img src="https://pic1.zhimg.com/80/v2-993752f09bf67b6d8700397f98a83cde_720w.jpg" alt=""></p> <p>你可以直接点击文件列表中的第一项ipynb文件，可以看到本教程的全部示例代码。</p> <p>你可以一边看教程的讲解，一边依次执行这些代码。</p> <p><img src="https://pic1.zhimg.com/v2-5210b2e8ca06bb6af5d2beb9b1d4abaa_b.jpg" alt=""></p> <p><img src="https://pic1.zhimg.com/80/v2-5210b2e8ca06bb6af5d2beb9b1d4abaa_720w.jpg" alt=""></p> <p>但是，我<strong>建议</strong>的方法，是回到主界面下，新建一个新的空白 Python 3 笔记本。</p> <p><img src="https://pic2.zhimg.com/v2-7da692c85db58877b04418bb6d51faa0_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-7da692c85db58877b04418bb6d51faa0_720w.jpg" alt=""></p> <p>请跟着教程，一个个字符输入相应的内容。这可以帮助你更为深刻地理解代码的含义，更高效地把技能内化。</p> <p><img src="https://pic3.zhimg.com/v2-06b302acf33e8de028cf3db35043da60_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-06b302acf33e8de028cf3db35043da60_720w.jpg" alt=""></p> <p>准备工作结束，下面我们开始正式输入代码。</p> <h2 id="代码">代码</h2> <p>读入网页加以解析抓取，需要用到的软件包是 requests_html 。我们此处并不需要这个软件包的全部功能，只读入其中的 HTMLSession 就可以。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>from requests_html import HTMLSession
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>然后，我们建立一个会话（session），即让Python作为一个客户端，和远端服务器交谈。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>session = HTMLSession()
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>前面说了，我们打算采集信息的网页，是《<a href="https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/85f4624485b9" target="_blank" rel="noopener noreferrer">如何用《玉树芝兰》入门数据科学？<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>》一文。</p> <p>我们找到它的网址，存储到url变量名中。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>url = 'https://www.jianshu.com/p/85f4624485b9'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>下面的语句，利用 session 的 get 功能，把这个链接对应的网页整个儿取回来。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>r = session.get(url)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>网页里面都有什么内容呢？</p> <p>我们告诉Python，请把服务器传回来的内容当作HTML文件类型处理。我不想要看HTML里面那些乱七八糟的格式描述符，只看文字部分。</p> <p>于是我们执行：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>print(r.html.text)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这就是获得的结果了：</p> <p><img src="https://pic3.zhimg.com/v2-dd1b68203f2e69fdc33bc5e4a703fd5b_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-dd1b68203f2e69fdc33bc5e4a703fd5b_720w.jpg" alt=""></p> <p>我们心里有数了。取回来的网页信息是正确的，内容是完整的。</p> <p>好了，我们来看看怎么趋近自己的目标吧。</p> <p>我们先用<strong>简单粗暴</strong>的方法，尝试获得网页中包含的全部链接。</p> <p>把返回的内容作为HTML文件类型，我们查看 links 属性：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>r.html.links
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这是返回的结果：</p> <p><img src="https://picb.zhimg.com/v2-12571f2c08f2912641b280f55e1d0dcb_b.jpg" alt=""></p> <p><img src="https://picb.zhimg.com/80/v2-12571f2c08f2912641b280f55e1d0dcb_720w.jpg" alt=""></p> <p>这么多链接啊！</p> <p>很兴奋吧？</p> <p>不过，你发现没有？这里许多链接，看似都不完全。例如第一条结果，只有：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>'/'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这是什么东西？是不是链接抓取错误啊？</p> <p>不是，这种看着不像链接的东西，叫做相对链接。它是某个链接，相对于我们采集的网页所在域名（<a href="https://link.zhihu.com/?target=https%3A//www.jianshu.com" target="_blank" rel="noopener noreferrer">https://www.jianshu.com<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>）的路径。</p> <p>这就好像我们在国内邮寄快递包裹，填单子的时候一般会写“XX省XX市……”，前面不需要加上国家名称。只有国际快递，才需要写上国名。</p> <p>但是如果我们希望获得全部可以直接访问的链接，怎么办呢？</p> <p>很容易，也只需要一条 Python 语句。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>r.html.absolute_links
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这里，我们要的是“绝对”链接，于是我们就会获得下面的结果：</p> <p><img src="https://pic2.zhimg.com/v2-79992f8986642d87f451aea394ad42f7_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-79992f8986642d87f451aea394ad42f7_720w.jpg" alt=""></p> <p>这回看着是不是就舒服多了？</p> <p>我们的任务已经完成了吧？链接不是都在这里吗？</p> <p>链接确实都在这里了，可是跟我们的目标是不是有区别呢？</p> <p>检查一下，确实有。</p> <p>我们不光要找到链接，还得找到链接对应的描述文字呢，结果里包含吗？</p> <p>没有。</p> <p>结果列表中的链接，都是我们需要的吗？</p> <p>不是。看长度，我们就能感觉出许多链接并不是文中描述其他数据科学文章的网址。</p> <p>这种简单粗暴直接罗列HTML文件中所有链接的方法，对本任务行不通。</p> <p>那么我们该怎么办？</p> <p>我们得学会跟 Python 说清楚我们要找的东西。这是网页抓取的<strong>关键</strong>。</p> <p>想想看，如果你想让助手（人类）帮你做这事儿，怎么办？</p> <p>你会告诉他：</p> <p>“寻找正文中全部可以点击的蓝色文字链接，拷贝文字到Excel表格，然后右键复制对应的链接，也拷贝到Excel表格。每个链接在Excel占一行，文字和链接各占一个单元格。”</p> <p>虽然这个操作执行起来麻烦，但是助手听懂后，就能帮你执行。</p> <p>同样的描述，你试试说给电脑听……不好意思，它不理解。</p> <p>因为你和助手看到的网页，是这个样子的。</p> <p><img src="https://pic4.zhimg.com/v2-781e1e2b912fc0f367b10eb69a9b7b27_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-781e1e2b912fc0f367b10eb69a9b7b27_720w.jpg" alt=""></p> <p>电脑看到的网页，是这个样子的。</p> <p><img src="https://pic3.zhimg.com/v2-d1b27658279c1e342fde8a207d765c22_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-d1b27658279c1e342fde8a207d765c22_720w.jpg" alt=""></p> <p>为了让你看得清楚源代码，浏览器还特意对不同类型的数据用了颜色区分，对行做了编号。</p> <p>数据显示给电脑时，上述辅助可视功能是没有的。它只能看见一串串字符。</p> <p>那可怎么办？</p> <p>仔细观察，你会发现这些HTML源代码里面，文字、图片链接内容前后，都会有一些被尖括号括起来的部分，这就叫做“标记”。</p> <p>所谓HTML，就是一种标记语言（超文本标记语言，HyperText Markup Language）。</p> <p>标记的作用是什么？它可以把整个的文件分解出层次来。</p> <p><img src="https://pic2.zhimg.com/v2-2a6e626c67fdddb07bbb5b1259f99283_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-2a6e626c67fdddb07bbb5b1259f99283_720w.jpg" alt=""></p> <p>（图片来源：<a href="https://link.zhihu.com/?target=https%3A//goo.gl/kWCqS6" target="_blank" rel="noopener noreferrer">https://goo.gl/kWCqS6<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>）</p> <p>如同你要发送包裹给某个人，可以按照“省-市-区-街道-小区-门牌”这样的结构来写地址，快递员也可以根据这个地址找到收件人。</p> <p>同样，我们对网页中某些特定内容感兴趣，可以依据这些标记的结构，顺藤摸瓜找出来。</p> <p>这是不是意味着，你必须先学会HTML和CSS，才能进行网页内容抓取呢？</p> <p>不是的，我们可以借助工具，帮你显著简化任务复杂度。</p> <p>这个工具，Google Chrome浏览器自带。</p> <p>我们在样例文章页面上，点击鼠标右键，在出现的菜单里面选择“检查”。</p> <p><img src="https://picb.zhimg.com/v2-d12d92ce3f4293690282a5f6730148b0_b.jpg" alt=""></p> <p><img src="https://picb.zhimg.com/80/v2-d12d92ce3f4293690282a5f6730148b0_720w.jpg" alt=""></p> <p>这时，屏幕下方就会出现一个分栏。</p> <p><img src="https://pic2.zhimg.com/v2-430c8e8633986e99f0244b0f23fd8159_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-430c8e8633986e99f0244b0f23fd8159_720w.jpg" alt=""></p> <p>我们点击这个分栏左上角（上图红色标出）的按钮。然后把鼠标悬停在第一个文内链接（《玉树芝兰》）上面，点击一下。</p> <p>￼</p> <p><img src="https://picb.zhimg.com/v2-025becdb0060210af65dbf689f08a3ee_b.jpg" alt=""></p> <p><img src="https://picb.zhimg.com/80/v2-025becdb0060210af65dbf689f08a3ee_720w.jpg" alt=""></p> <p>此时，你会发现下方分栏里面，内容也发生了变化。这个链接对应的源代码被放在分栏区域正中，高亮显示。</p> <p><img src="https://pic3.zhimg.com/v2-b83ac27b938ea376f719dbf84f501eb6_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-b83ac27b938ea376f719dbf84f501eb6_720w.jpg" alt=""></p> <p>确认该区域就是我们要找的链接和文字描述后，我们鼠标右键选择高亮区域，并且在弹出的菜单中，选择 Copy -&gt; Copy selector。</p> <p><img src="https://pic2.zhimg.com/v2-bb05a841dda4fb2f6c16a4c17638f8d7_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-bb05a841dda4fb2f6c16a4c17638f8d7_720w.jpg" alt=""></p> <p>找一个文本编辑器，执行粘贴，就可以看见我们究竟复制下来了什么内容。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>body &gt; div.note &gt; div.post &gt; div.article &gt; div.show-content &gt; div &gt; p:nth-child(4) &gt; a
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这一长串的标记，为电脑指出了：请你先找到 body 标记，进入它管辖的这个区域后去找 <code>div.note</code> 标记，然后找……最后找到 a 标记，这里就是要找的内容了。</p> <p>回到咱们的 Jupyter Notebook 中，用刚才获得的标记路径，定义变量sel。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>sel = 'body &gt; div.note &gt; div.post &gt; div.article &gt; div.show-content &gt; div &gt; p:nth-child(4) &gt; a'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>我们让 Python 从返回内容中，查找 sel 对应的位置，把结果存到 results 变量中。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>results = r.html.find(sel)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>我们看看 results 里面都有什么。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>results
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这是结果：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>[&lt;Element 'a' href='https://www.jianshu.com/nb/130182' target='_blank'&gt;]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>results 是个列表，只包含一项。这一项包含一个网址，就是我们要找的第一个链接（《玉树芝兰》）对应的网址。</p> <p>可是文字描述“《玉树芝兰》”哪里去了？</p> <p>别着急，我们让 Python 显示 results 结果数据对应的文本。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>results[0].text
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这是输出结果：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>'玉树芝兰'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>我们把链接也提取出来：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>results[0].absolute_links
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>显示的结果却是一个集合。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>{'https://www.jianshu.com/nb/130182'}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>我们不想要集合，只想要其中的链接字符串。所以我们先把它转换成列表，然后从中提取第一项，即网址链接。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>list(results[0].absolute_links)[0]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这次，终于获得我们想要的结果了：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>'https://www.jianshu.com/nb/130182'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>有了处理这第一个链接的经验，你信心大增，是吧？</p> <p>其他链接，也无非是找到标记路径，然后照猫画虎嘛。</p> <p>可是，如果每找一个链接，都需要手动输入上面这若干条语句，那也太麻烦了。</p> <p>这里就是编程的技巧了。重复逐条运行的语句，如果工作顺利，我们就要尝试把它们归并起来，做个简单的函数。</p> <p>对这个函数，只需给定一个选择路径（sel），它就把找到的所有描述文本和链接路径都返回给我们。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>def get_text_link_from_sel(sel):
    mylist = []
    try:
        results = r.html.find(sel)
        for result in results:
            mytext = result.text
            mylink = list(result.absolute_links)[0]
            mylist.append((mytext, mylink))
        return mylist
    except:
        return None
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>我们测试一下这个函数。</p> <p>还是用刚才的标记路径（sel）不变，试试看。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>print(get_text_link_from_sel(sel))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>输出结果如下：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>[('玉树芝兰', 'https://www.jianshu.com/nb/130182')]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>没问题，对吧？</p> <p>好，我们试试看第二个链接。</p> <p>我们还是用刚才的方法，使用下面分栏左上角的按钮点击第二个链接。</p> <p><img src="https://pic4.zhimg.com/v2-f26c7512fb92559344ca69edb975f030_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-f26c7512fb92559344ca69edb975f030_720w.jpg" alt=""></p> <p>下方出现的高亮内容就发生了变化：</p> <p><img src="https://pic4.zhimg.com/v2-f2c49aff866ffca031dcfdc24c6b9e81_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-f2c49aff866ffca031dcfdc24c6b9e81_720w.jpg" alt=""></p> <p>我们还是用鼠标右键点击高亮部分，拷贝出 selector。</p> <p><img src="https://pic2.zhimg.com/v2-d33f721173a4cc9f4aa00dd79b7e0c64_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-d33f721173a4cc9f4aa00dd79b7e0c64_720w.jpg" alt=""></p> <p>然后我们直接把获得的标记路径写到 Jupyter Notebook 里面。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>sel = 'body &gt; div.note &gt; div.post &gt; div.article &gt; div.show-content &gt; div &gt; p:nth-child(6) &gt; a'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>用我们刚才编制的函数，看看输出结果是什么？</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>print(get_text_link_from_sel(sel))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>输出如下：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>[('如何用Python做词云？', 'https://www.jianshu.com/p/e4b24a734ccc')]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>检验完毕，函数没有问题。</p> <p>下一步做什么？</p> <p>你还打算去找第三个链接，仿照刚才的方法做？</p> <p>那你还不如全文手动摘取信息算了，更省事儿一些。</p> <p>我们要想办法把这个过程<strong>自动化</strong>。</p> <p>对比一下刚刚两次我们找到的标记路径：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>body &gt; div.note &gt; div.post &gt; div.article &gt; div.show-content &gt; div &gt; p:nth-child(4) &gt; a
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>以及：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>body &gt; div.note &gt; div.post &gt; div.article &gt; div.show-content &gt; div &gt; p:nth-child(6) &gt; a
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>发现什么规律没有？</p> <p>对，路径上其他的标记全都是一样的，唯独倒数第二个标记（&quot;p&quot;）后冒号后内容有区别。</p> <p>这就是我们自动化的关键了。</p> <p>上述两个标记路径里面，因为指定了在第几个“子”(<code>nth-child</code>)文本段（paragraph,也就是&quot;p&quot;代表的含义）去找&quot;a&quot;这个标记，因此只返回来单一结果。</p> <p>如果我们不限定&quot;p&quot;的具体位置信息呢？</p> <p>我们试试看，这次保留标记路径里面其他全部信息，只修改&quot;p&quot;这一点。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>sel = 'body &gt; div.note &gt; div.post &gt; div.article &gt; div.show-content &gt; div &gt; p &gt; a'
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>再次运行我们的函数：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>print(get_text_link_from_sel(sel))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这是输出结果：</p> <p><img src="https://pic1.zhimg.com/v2-98ae6bc8f9d5286bc9c69cda5d03cd93_b.jpg" alt=""></p> <p><img src="https://pic1.zhimg.com/80/v2-98ae6bc8f9d5286bc9c69cda5d03cd93_720w.jpg" alt=""></p> <p>好了，我们要找的内容，全都在这儿了。</p> <p>但是，我们的工作还没完。</p> <p>我们还得把采集到的信息输出到Excel中保存起来。</p> <p>还记得我们常用的数据框工具 Pandas 吗？又该让它大显神通了。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>import pandas as pd
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>只需要这一行命令，我们就能把刚才的列表变成数据框：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>df = pd.DataFrame(get_text_link_from_sel(sel))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>让我们看看数据框内容：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>df
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="https://pic2.zhimg.com/v2-fe01af1eb29c5294619ffc14b9da0c40_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-fe01af1eb29c5294619ffc14b9da0c40_720w.jpg" alt=""></p> <p>内容没问题，不过我们对表头不大满意，得更换为更有意义的列名称：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>df.columns = ['text', 'link']
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>再看看数据框内容：</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>df
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="https://pic3.zhimg.com/v2-a079ecf80b3c91c847de83121df883a3_b.jpg" alt=""></p> <p><img src="https://pic3.zhimg.com/80/v2-a079ecf80b3c91c847de83121df883a3_720w.jpg" alt=""></p> <p>好了，下面就可以把抓取的内容输出到Excel中了。</p> <p>Pandas内置的命令，就可以把数据框变成csv格式，这种格式可以用Excel直接打开查看。</p> <div class="language-text line-numbers-mode"><pre class="language-text"><code>df.to_csv('output.csv', encoding='gbk', index=False)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>注意这里需要指定encoding（编码）为gbk，否则默认的utf-8编码在Excel中查看的时候，有可能是乱码。</p> <p>我们看看最终生成的csv文件吧。</p> <p><img src="https://pic4.zhimg.com/v2-d2d9162f176b8edae706997524be0644_b.jpg" alt=""></p> <p><img src="https://pic4.zhimg.com/80/v2-d2d9162f176b8edae706997524be0644_720w.jpg" alt=""></p> <p>很有成就感，是不是？</p> <h2 id="小结">小结</h2> <p>本文为你展示了用Python自动网页抓取的基础技能。希望阅读并动手实践后，你能掌握以下知识点：</p> <ul><li>网页抓取与网络爬虫之间的联系与区别；</li> <li>如何用 pipenv 快速构建指定的 Python 开发环境，自动安装好依赖软件包；</li> <li>如何用 Google Chrome 的内置检查功能，快速定位感兴趣内容的标记路径；</li> <li>如何用 requests-html 包来解析网页，查询获得需要的内容元素；</li> <li>如何用 Pandas 数据框工具整理数据，并且输出到 Excel。</li></ul> <p>或许，你觉得这篇文章过于浅白，不能满足你的要求。</p> <p>文中只展示了如何从一个网页抓取信息，可你要处理的网页成千上万啊。</p> <p>别着急。</p> <p>本质上说，抓取一个网页，和抓取10000个网页，在流程上是一样的。</p> <p>而且，从咱们的例子里，你是不是已经尝试了抓取链接？</p> <p>有了链接作为基础，你就可以滚雪球，让Python爬虫“爬”到解析出来的链接上，做进一步的处理。</p> <p>将来，你可能还要应对实践场景中的一些棘手问题：</p> <ul><li>如何把抓取的功能扩展到某一范内内的所有网页？</li> <li>如何爬取Javascript动态网页？</li> <li>假设你爬取的网站对每个IP的访问频率做出限定，怎么办？</li> <li>……</li></ul> <p>这些问题的解决办法，我希望在今后的教程里面，一一和你分享。</p> <p>需要注意的是，网络爬虫抓取数据，虽然功能强大，但学习与实践起来有一定门槛。</p> <p>当你面临数据获取任务时，应该先检查一下这个清单：</p> <ul><li>有没有别人已经整理好的数据集合可以直接下载？</li> <li>网站有没有对你需要的数据提供API访问与获取方式？</li> <li>有没有人针对你的需求，编好了定制爬虫，供你直接调用？</li></ul> <p>如果答案是都没有，才需要你自己编写脚本，调动爬虫来抓取。</p> <p>为了巩固学习的知识，请你换一个其他网页，以咱们的代码作为基础修改后，抓取其中你感兴趣的内容。</p> <p>如果能把你抓取的过程记录下来，在评论区将记录链接分享给大家，就更好了。</p> <p>因为<strong>刻意练习</strong>是掌握实践技能的最好方式，而<strong>教是最好的学</strong>。</p> <p>祝顺利！</p> <h2 id="思考">思考</h2> <p>本文主要内容讲解完毕。</p> <p>这里给你提一个疑问，供你思考：</p> <p>我们解析并且存储的链接，其实是有重复的：</p> <p><img src="https://pic2.zhimg.com/v2-9259177982f2f2f68d2e199145f53094_b.jpg" alt=""></p> <p><img src="https://pic2.zhimg.com/80/v2-9259177982f2f2f68d2e199145f53094_720w.jpg" alt=""></p> <p>这并不是我们的代码有误，而是在《<a href="https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/85f4624485b9" target="_blank" rel="noopener noreferrer">如何用《玉树芝兰》入门数据科学？<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>》一文里，本来就多次引用过一些文章，所以重复的链接就都被抓取出来了。</p> <p>但是你存储的时候，也许不希望保留重复链接。</p> <p>这种情况下，你该如何修改代码，才能保证抓取和保存的链接没有重复呢？</p> <h2 id="讨论">讨论</h2> <p>你对Python爬虫感兴趣吗？在哪些数据采集任务上使用过它？有没有其他更高效的方式，来达成数据采集目的？欢迎留言，把你的经验和思考分享给大家，我们一起交流讨论。</p> <p>如果你对我的文章感兴趣，欢迎点赞，并且微信关注和置顶我的公众号“玉树芝兰”(nkwangshuyi)。</p> <p>如果本文可能对你身边的亲友有帮助，也欢迎你把本文通过微博或朋友圈分享给他们。让他们一起参与到我们的讨论中来。</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/solider245/VuePress-blog/edit/gh-pages/docs/Python/爬虫案例/如何用Python爬数据-网页抓取.md" target="_blank" rel="noopener noreferrer">你要教我做事咯？</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">8/8/2020, 6:41:31 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/VuePress-blog/Python/爬虫案例/【已解决】写Python爬虫爬取汽车之家品牌车系车型数据.html" class="prev">
        【已解决】写Python爬虫爬取汽车之家品牌车系车型数据
      </a></span> <span class="next"><a href="/VuePress-blog/Python/爬虫案例/实战项目 1：5 行代码爬取国内所有上市公司信息.html">
        实战项目 1：5 行代码爬取国内所有上市公司信息
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/VuePress-blog/assets/js/app.e4354aa1.js" defer></script><script src="/VuePress-blog/assets/js/2.398f4283.js" defer></script><script src="/VuePress-blog/assets/js/55.bf5c3551.js" defer></script>
  </body>
</html>
